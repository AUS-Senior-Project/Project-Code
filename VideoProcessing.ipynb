{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Install necessary packages ----------\n",
    "%pip install numpy pandas opencv-python torch torchvision scikit-learn matplotlib tqdm pillow timm pyyaml joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa8f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Import necessary libraries ----------\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights, inception_v3, Inception_V3_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28b151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Training on CPU...\n"
     ]
    }
   ],
   "source": [
    "# ---------- Device setup and check GPU availability ----------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA is available! Training on GPU...\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- config ----------\n",
    "ROOT = Path(\".\")  # Project-Code root\n",
    "CSV_FALL = ROOT / \"FallDetectionLabels.csv\"\n",
    "CSV_GEST = ROOT / \"HandGestureLabels.csv\"\n",
    "\n",
    "DATASET_DIR = ROOT / \"Dataset\"\n",
    "OUT_FALL = ROOT / \"Processed Dataset\" / \"ProcessedFallDetection\"\n",
    "OUT_GEST = ROOT / \"Processed Dataset\" / \"ProcessedHandGesture\"\n",
    "\n",
    "PROCESSED_CSV_FALL = ROOT / \"ProcessedFallDetection.csv\"\n",
    "PROCESSED_CSV_GEST = ROOT / \"ProcessedHandGesture.csv\"\n",
    "\n",
    "SAMPLE_EVERY = 5\n",
    "OUT_SIZE = 600  # EfficientNet-B7 scale\n",
    "OVERWRITE = True\n",
    "VIDEO_EXTS = [\".mp4\", \".avi\", \".mov\", \".mkv\", \".MP4\", \".AVI\", \".MOV\", \".MKV\"]\n",
    "\n",
    "\n",
    "# ---------- utils ----------\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def resolve_video_path(rel_path: str) -> Path:\n",
    "    \"\"\"\n",
    "    rel_path may be:\n",
    "      - a file path with extension\n",
    "      - a file path without extension\n",
    "      - a directory containing a single video\n",
    "    Returns absolute path or raises FileNotFoundError.\n",
    "    \"\"\"\n",
    "    p = ROOT / rel_path\n",
    "    if p.is_file():\n",
    "        return p\n",
    "\n",
    "    if p.suffix == \"\" and p.with_suffix(\".mp4\").is_file():\n",
    "        return p.with_suffix(\".mp4\")\n",
    "\n",
    "    if p.is_dir():\n",
    "        # pick first known video file\n",
    "        for ext in VIDEO_EXTS:\n",
    "            vids = sorted(p.glob(f\"*{ext}\"))\n",
    "            if vids:\n",
    "                return vids[0]\n",
    "\n",
    "    # try any matching extension at same parent\n",
    "    if p.suffix == \"\":\n",
    "        for ext in VIDEO_EXTS:\n",
    "            cand = p.with_suffix(ext)\n",
    "            if cand.is_file():\n",
    "                return cand\n",
    "\n",
    "    raise FileNotFoundError(f\"Video not found for entry: {rel_path}\")\n",
    "\n",
    "\n",
    "def pad_to_square(img: np.ndarray) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    s = max(h, w)\n",
    "    top = (s - h) // 2\n",
    "    bottom = s - h - top\n",
    "    left = (s - w) // 2\n",
    "    right = s - w - left\n",
    "    return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "\n",
    "def process_video_to_motion_image(video_path: Path, sample_every: int = 5, out_size: int = 600) -> np.ndarray:\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open {video_path}\")\n",
    "\n",
    "    sampled = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if idx % sample_every == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            sampled.append(gray.astype(np.float32))\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "\n",
    "    if len(sampled) < 2:\n",
    "        raise RuntimeError(f\"Not enough sampled frames ({len(sampled)}) in {video_path}\")\n",
    "\n",
    "    # differences with per-frame median threshold\n",
    "    acc = np.zeros_like(sampled[0], dtype=np.float32)\n",
    "    prev = sampled[0]\n",
    "    for cur in sampled[1:]:\n",
    "        diff = np.abs(cur - prev)\n",
    "        thr = np.median(diff)\n",
    "        # keep values above threshold, zero below\n",
    "        mask = diff >= thr\n",
    "        acc[mask] += diff[mask]\n",
    "        prev = cur\n",
    "\n",
    "    # normalize 0..1 by max, then scale to 0..255 uint8\n",
    "    m = acc.max()\n",
    "    if m > 0:\n",
    "        acc = acc / m\n",
    "    acc = (acc * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    # pad to square and resize\n",
    "    acc = pad_to_square(acc)\n",
    "    acc = cv2.resize(acc, (out_size, out_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # stack to 3 channels\n",
    "    img3 = np.stack([acc, acc, acc], axis=2)\n",
    "    return img3\n",
    "\n",
    "\n",
    "def target_path_for_output(out_root: Path, rel_video_path: str, ext: str = \".png\") -> Path:\n",
    "    \"\"\"\n",
    "    Mirrors the path under Dataset into the processed folder to avoid name collisions.\n",
    "    Example:\n",
    "      rel_video_path = 'Dataset/HandGesture/CurtainGesture/Hamad/CGH1.mp4'\n",
    "      -> OUT_GEST / 'HandGesture/CurtainGesture/Hamad/CGH1.png'\n",
    "    \"\"\"\n",
    "    rel = Path(rel_video_path)\n",
    "    # drop any drive/root artifacts and leading 'Dataset'\n",
    "    parts = list(rel.parts)\n",
    "    if parts and parts[0].lower() == \"dataset\":\n",
    "        parts = parts[1:]\n",
    "    rel_no_ext = Path(*parts).with_suffix(ext)\n",
    "    return out_root / rel_no_ext\n",
    "\n",
    "\n",
    "def process_table(df: pd.DataFrame, out_root: Path, has_user: bool) -> pd.DataFrame:\n",
    "    records = []\n",
    "    failures = []\n",
    "\n",
    "    for row in tqdm(df.itertuples(index=False), total=len(df)):\n",
    "        rel_path = getattr(row, \"video_path\")\n",
    "        label = getattr(row, \"label\")\n",
    "        user_id = getattr(row, \"user_id\") if has_user else None\n",
    "\n",
    "        try:\n",
    "            abs_video = resolve_video_path(rel_path)\n",
    "            out_img = target_path_for_output(out_root, rel_path, ext=\".png\")\n",
    "            ensure_dir(out_img.parent)\n",
    "\n",
    "            if OVERWRITE or not out_img.exists():\n",
    "                img = process_video_to_motion_image(abs_video, sample_every=SAMPLE_EVERY, out_size=OUT_SIZE)\n",
    "                # write PNG\n",
    "                ok = cv2.imwrite(str(out_img), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "                if not ok:\n",
    "                    raise RuntimeError(\"cv2.imwrite failed\")\n",
    "\n",
    "            rel_img = out_img.relative_to(ROOT).as_posix()\n",
    "            rec = {\"image_path\": rel_img, \"label\": label, \"video_path\": rel_path}\n",
    "            if has_user:\n",
    "                rec[\"user_id\"] = user_id\n",
    "            records.append(rec)\n",
    "\n",
    "        except Exception as e:\n",
    "            failures.append({\"video_path\": rel_path, \"label\": label, \"error\": str(e)})\n",
    "\n",
    "    if failures:\n",
    "        fail_csv = out_root / \"processing_failures.csv\"\n",
    "        pd.DataFrame(failures).to_csv(fail_csv, index=False)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    ensure_dir(OUT_FALL)\n",
    "    ensure_dir(OUT_GEST)\n",
    "\n",
    "    # Fall dataset\n",
    "    if CSV_FALL.exists():\n",
    "        df_fall = pd.read_csv(CSV_FALL)\n",
    "        # expected columns: video_path, label\n",
    "        out_fall_df = process_table(df_fall, OUT_FALL, has_user=False)\n",
    "        out_fall_df.to_csv(PROCESSED_CSV_FALL, index=False)\n",
    "    else:\n",
    "        print(f\"Missing CSV: {CSV_FALL}\")\n",
    "\n",
    "    # Gesture dataset\n",
    "    if CSV_GEST.exists():\n",
    "        df_gest = pd.read_csv(CSV_GEST)\n",
    "        # expected columns: video_path, label, user_id\n",
    "        out_gest_df = process_table(df_gest, OUT_GEST, has_user=True)\n",
    "        out_gest_df.to_csv(PROCESSED_CSV_GEST, index=False)\n",
    "    else:\n",
    "        print(f\"Missing CSV: {CSV_GEST}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
